# Loss and Delay

왜 패킷 전송할때 딜레이와 로스가 일어나는가? 라우터의 버퍼에서 일어난다.

라우터는 패킷 여러개를 함께 포워드하기 때문에 한 라우터에 패킷이 몰릴 수 있다. 그러면 패킷을 로컬 버퍼라는 곳에 queue로 넣어 놨다가 처리한다. 

이때 패킷이 도착하는 속도 arrival rate가 output link의 capacity보다 높으면, 즉 버퍼 용량이 모자라면 못 들어온 패킷은 버린다. -> loss

## delay의 4가지 원인

한 노드의 delay를 d nodal이라고 한다.

d nodal = d proc + d queue + d trans + d prop

### d proc (nodal processing)
- check bit errors: 에러 있는지 확인
- determine output link: 라우터는 전체를 보고 다음 노드가 뭔지 알려준다
  - (pingpong: 계속 돌음)서비스에 따라 돌아가도 되는지 바로 가야하는지 다름. 메일은 타임에 민감하지 않음. 실시간이 중요한 데이터도 있음. 이런건 타임 조정이 필요함. ttl 오버했는지 어디에 몇번이나 갔는지 보고 버림.

### d queue (queueing delay)
- 로컬버퍼에서 기다리는 시간.
- 그 라우터의 정체된 정도에 따라 다름

### d trans (transmission delay)
- l(packet length bits) / r(link transmission rate bps)
- 여기서의 r 전송 속도는 링크의 대역폭(bandwidth) 즉 패킷을 링크로 밀어넣는데 걸리는 시간이다. 패킷 크기가 클수록 커진다.

### d prop (propagation delay)
- d(length of physical link) / s(propagation speed)
- 여기서의 s 전송 속도는 링크의 전파 속도이다. 패킷 크기와 무관하다. 링크가 길수록 커진다. 전기 신호가 이동하는 시간.

## caravan 비유
- 차는 bit, 차의 행렬은 packet
- 차는 100km/hr 속도로 전파한다.
- 톨게이트는 12초 동안 transmission 한다.
- 톨게이트 간 사이는 100km이다.
- 10대의 차가 두 번째 톨게이트에 도착하는 데 걸리는 시간은?

=> 톨게이트로 밀어넣는 시간 = 10*12초 = 2분, 마지막 차가 2번째 톨게이트까지 가는데 1시간 => 62분.

- 차는 1000km/hr로 전파
- 톨게이트는 1분 걸림
- 모든 차가 첫번째 톨게이트를 통과하기 전에 두번째 톨게이트에 도착하는 차가 있을까?

=> 모든 차가 톨게이트를 지나가는 시간 10*60초 = 10분, 차 한 대가 두번째 톨게이트까지 전파하는 시간 1/10시간=6분 => 7분 후 첫번째 차가 두번째 톨게이트에 도착하고 3대가 첫 톨게이트에 있다.


## Queueing Delay
La/R transmission delay는 곧 '시스템이 감당해야 하는 부하'이다
이 값이 1을 넘는 순간부터는 처리 능력보다 일이 더 많이 들어와서 지연이 폭발한다. 왜 1일까?

- L: 패킷 길이(bits)
- a: 초당 도착하는 패킷 수(packets/sec)
- R: 링크 대역폭(bits/sec)

1초 동안 도착하는 비트 수 = L * a
1초 동안 링크가 처리할 수 있는 비트 수 = R

따라서 La/R = 도착 비트율/처리 비트율 = 시스템 부하율

La/R < 1
- 도착량이 처리량보다 적다. 지연이 적고 안정적

La/R = 1
- 도착량 = 처리량
- 꽉 찬 상태

La/R > 1
- 도착량이 처리량보다 많다. 들어오는 패킷이 항상 나가는 패킷보다 많다. 줄이 무한정 쌓인다. 평균 지연이 이론적으로 무한대가 된다.





### traceroute
소스에서 라우터까지의 딜레이를 측정. 패킷 3개를 라우터 i로 보냄 -> 라우터 i가 패킷을 전송자에게 돌려보냄 -> 전송자가 transmission과 reply의 시간차를 측정함.



## Packet loss
꽉 찬 큐에 들어오는 패킷은 버려진다. 버려진 패킷은 이전 노드에 의해 재전송될 수도 있고 아닐 수도 있다.

## throughput
bit이 sender에서 receiver로 가는 rate(bits/시간단위)
- instantaneous: 특정 시점에서의 rate
- average: 특정 시간에 걸친 rate

어느 길로 가는지, 장비의 상황, 받는 서버 상태 등에 따라 다름.
bottleneck link: end-end throughput을 깎아먹는 링크

connection은 링크 1개가 아니라 end-to-end 트래픽 흐름 1개다. connection은 여러 링크를 포함한다.
서버->클라이언트는 downstream, 클라이언트->서버는 upstream이다.

end-to-end throughput은 평균인줄알았는데 아니고 가장 느린 링크(bottleneck rate)의 rate였다.

만약 N개의 connection이 하나의 병목 링크 R을 공유한다면 각 connection의 throughput은 R/N이다.




# network security
원래 인터넷은 서로 믿는 연구자들이 쓰는 네트워크로 만들어져서 보안을 별로 고려하지 않았다. 나중에 전세계에 퍼지면서 프로토콜 설계자들이 보안을 추가하는 상황이 되었다. 예를 들어 HTTP->HTTPS, DNS->DNSSEC, 이메일->TLS

나쁜놈들은 인터넷을 통해 host에게 malware를 넣는다. malware는 virus, worm에 의해 host로 들어갈 수 있다. 둘다 감염을 자기복제한다.
virus는 받아서 실행하면 작동, worm은 받으면 스스로 실행함.

spyware malware는 키 누름, 웹사이트 방문, 정보 올림 등을 기록할 수 있다. 감염된 host는 botnet에 등록되어 스팸이나 ddos에 이용될 수 있다.

## dos
denial of service. 공격자가 가짜 트래픽으로 서버와 대역폭 같은 자원을 점령해서 그걸 사용해야 하는 트래픽이 못 쓰게 한다.

ddos: distribute of dos. botnet에 등록된 좀비컴퓨터 수백개가 하나의 서버에 많은 메세지를 보냄 -> 서버가 메세지 처리하느라(three way hand shake) 원래 해야 하는 일을 못함.

## sniffing
공유 ethernet, 무선 LAN 등에서는 패킷이 여러 장치에게 전파된다. 그래서 네트워크에 연결된 장치라면 원래 자기 것이 아닌 패킷도 볼 수 있는 위치에 놓인다.
스니핑 도구가 네트워크 구간에 접근해서 자신의 NIC를 promiscuous mode로 바꾸면 나와 상관없는 지나가는 패킷을 다 도청할 수 있다.

## ip spoofing
가짜 address가 담긴 packet을 보냄





# Protocol layers
각각의 레이어가 계층화되어있고 같은 계층은 같은 서비스를 제공
왜 레이어를 할까? 시스템이 복잡하기 때문이다. 

- application(IMAP메일서버,SMTP메일서버,HTTP): app을 지원
- transport(TCP,UDP): process간의 데이터 전달
- network(IP, routing protocols): IP주소 기반으로 라우팅.
- link(Ethernet, WIFI, PPP): 인접한 네트워크 요소들 사이 데이터 전달
- physical: wire 위의 bit

## Encapsulation
한 개의 계층을 내려갈 떄마다 내려가는 계층에서 필요한 header를 붙여줌.
destination에서는 link에서 받아서 거꾸로 헤더를 떼면서 위로 올려줌

switch는 forwarding하는 link까지부터 있음. 한개만
router는 routing하니까 network부터 있음. 멀티







# application layer
end system에서 실행되고, 네트워크에서 소통하는 프로그램을 만들려면 -> 네트워크 코어 장치들을 위한 코드를 쓸 필요는 없다. 네트워크 코어 장치들은 application을 실행하지 않는다. end system에서만 applicaion을 다루는 것은 효율적이다.

## cs(client-server)구조
- 서버: 서버가 먼저 실행되고 있어야. 서버는 고정된 ip주소를 가지고 있다. 서버는 보통 데이터센터에 있다. 해당 서버가 망하면 다 망함.
- 클라이언트: 서버와 소통한다. 동적 ip 주소를 가지고있을수도. 클라이언트끼리 직접 소통하지 않는다.

## peer-to-peer 구조
항상 돌아가고 있는 서버가 필요하지 않다. 분산. end system들끼리 직접 소통한다. 참여하는 peer가 다른 peer에게 request하고, provide한다 -> self scalability. 새로운 peer는 새로운 capacity+새로운 demand를 가져온다.
peer들은 간헐적으로 연결되고, ip 주소를 바꾼다. 그래서 관리가 복잡하다.
토렌토, 비트코인. P2P file sharing

# process
host에 의해 실행되는 program
- inter-process communication: 한 host에서 두 process가 소통
- messages: 서로 다른 host 사이 message 주고받으며 소통

- client process: 소통을 시작하는 process
- server process: 접근을 기다리는 process
  - P2P 구조는 application이 client와 server process를 함께 갖고있다?

## Socket
process들은 자신의 socket으로부터 message를 전송하고 받는다.
socket은 문과 같다. process가 다른 process로 보내는건 문을 두드리는 거임.

## addressing processes
- message를 받으려면 process는 identifier를 가져야 함. host device는 32-bit IP주소를 가지고 있다. 그걸 process가 담고있는다는건가? 하지만 그것만으로는 충분하지 않다. 한 host에서 여러개의 process가 실행되고 있어서 포트넘버도 구분해야됨.
- 포트넘버: process를 구분함. 
  - HTTP는 80, mail server는 25
  - 자주 사용되는 포트 well known port

identifier는 ip주소와 포트넘버를 포함한다.

## application layer protocol
- message의 종류에는 request와 response가 있음
- message의 문법은 message의 field들을 의미한다. RFC에 open protocol이 정의되어 있음. HTTP, SMTP등
- message의 의미론은 field에 있는 정보의 의미를 뜻한다.
- rules는 언제 어떻게 process들이 message들을 받고 전송하는지

app에 따라 어떤 transport service가 필요한지는 다르다.
- 데이터 무결성(파일전송, 웹 거래)
- 시간(웹 전화통신, 인터랙티브 게임)
- throughput 효율
- 보안



# tcp
- reliable. 데이터 유실이 있으면 안됨.
- flow control: 받는쪽에서 다 차면 그만보내야됨. timeout
- congestion control: 리시버뿐 아니라 네트워크 환경 전체 보고 복잡도가 올라가면 기다리기. 복잡도가 높음을 암시하는 신호들(응답 timeout)을 봐서 유추
- 타이밍, throughput, 보안은 tcp 단에서는 보장해주지 않음. app에서 해야
  
# udp
- 계속 보내기만함.빠르기만하면 됨.
- reliability, flow control, congestion control 없음.

TLS: transport layer security


## TCP 보안
- 원래 TCP, UDP socket은 보안이 없다. 비밀번호도 clearText임?
- TLS transpoprt layer security: 암호화된 tcp connection, 데이터 진실성, end-point 인증을 제공한다.

TSL을 application layer에서 구현하기: TSL 라이브러리
TLS socket API: clearText 암호화